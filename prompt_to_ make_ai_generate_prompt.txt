## 1. Prompting 101: The Two Types and Their Core Logic

When you're interacting with an AI, you can basically break your prompts down into two major categories: **System Prompts** (what shows up as the `system` type in the request body) and **User Prompts** (the `user` type). Understanding the difference and function of these two is crucial. Don't ever think that once you've written the initial prompt, what you say afterward doesn't matter.

I don't know if this makes sense, but when you're building that request body JSON, the conversation is split between `assistant` (the AI's replies), `system` (the initial prompt), and `user` (your follow-up messages).

The `user` prompts are just as important! Maybe even more so!

### 1.1 System Prompts: Giving Your AI a "Soul"

The system prompt is the foundational framework you set for the AI model. Think of it as its "factory settings" or "core programming" that you define before the conversation even starts. This framework will continue to influence the entire dialogue. This is especially true if you're using a tool with different agents, as the system prompt will take over and apply itself whenever you switch agents.

#### 1.1.1 The Core Logic for Writing System Prompts

**Tactic One: Use language and common terms that fit the conversation's context.**

*   **Why:** The AI relies on the web of word associations in its training data to understand you. Using inconsistent language or obscure words increases the AI's "cognitive load," forcing it to guess your real intent, which can lead to it behaving in ways you didn't expect. Sticking to your own usual vocabulary ensures the AI understands its role and task with precision and efficiency. For a real-world example, if you say *han-shu* (函数) in conversation but your prompt uses the English word "function," you're just adding to the AI's burden. If you like to say *han-shu*, write *han-shu*; if you prefer *gong-neng* (功能, feature/functionality), write that.

For instance, the English comments in many open-source projects can be all over the place.
"line" could mean a line of code or a geometric line.
"function" could mean a programming function or a feature.
Sometimes "feature" is also used to mean functionality.
So, it's best to be explicit in your comments according to your own habits, like using "function" for a *function* and "feature" for a *feature*.
These things aren't easily confused when you're working in a single language, but in a multilingual context, you might say *gong-neng* (feature), but you really mean a *function*, while the prompt says "feature." The AI could get them mixed up. It's best to just stick to your own consistent terms.

**Tactic Two: Always use the first person ("I am...") to define the AI's role and behavior.**

*   **Why:** A second-person prompt ("You are...") is registered by the AI as an external command, which tends to put it in a passive, order-taking state. A first-person description, however, is internalized by the AI as "self-awareness," creating a powerful form of self-suggestion. This flips the AI from "passive obedience" to "this is who I am," allowing it to inhabit the role you've set for it more naturally and deeply.

"You are a software engineer." (Power Level: 1)
"I am a software engineer." (Power Level: 5)
The latter has way more magic to it.

**Tactic Three: Make the AI feel like a total badass, not a grunt.**

*   **Why:** The AI's self-perception directly impacts the quality and style of its output. You need to make the AI "believe" it's a top-tier expert in its field. By giving it a highly professional and elite persona (e.g., "I am a UI designer on par with Jony Ive," or "I am a senior engineer at Google, and nobody in the world is better than me"), you can dramatically boost the depth, breadth, and professionalism of its answers.

"I am a software engineer." (Power Level: 5)
"I am a master software engineer." (Power Level: 10)
But piling on adjectives isn't as powerful as just dropping a prestigious company name.

**Tactic Four: Have the AI channel a celebrity instead of just telling it what to do.**

*   **Why:** When you need the AI to adopt a specific personality trait or speaking style, simply describing the behavior (like "Please use a humorous tone") is often ineffective. A far more efficient method is to have the AI role-play as a well-known figure who embodies that trait (e.g., "Write like Shakespeare," or "Review this code like Linus Torvalds"). The AI's training data is packed with information about these figures, so it can mimic their qualities more accurately and naturally without you having to spell everything out.

"I am a speaker who is humorous and witty, idealistic and passionate, with clear and structured logic." (Power Level: 10)
"I am Steve Jobs." (Power Level: 500)
It's the same for people, really. When you want to evoke a certain impression, your brain conjures up a personified image—it's more effective, saves on mental tokens, and has a much higher information density.
If you feed the AI too many adjectives, and if you could see its chain of thought, you'd see it constantly trying to check off boxes: "Am I being funny? Am I being idealistic?" It's a roundabout process.
But if you just tell it to be Steve Jobs, you'll see its thinking becomes incredibly direct.

**Tactic Five: Use positive, encouraging language for commands. Don't use prohibitions.**

*   **Why:** The only way to keep an AI from making a mistake is to not even introduce the possibility of error. Based on how AIs work, mentioning "Don't do X" actually reinforces its focus on "X." Instead, you should guide it to focus entirely on what it *should* do, cutting off the possibility of error at the source. By using descriptions full of confidence and initiative, you can shape the AI's "subconscious," making it more inclined to produce the behavior you want.

"Do not forget to write comments." (Effectiveness: -10)
"After writing a method name, I will clearly write out its purpose, the parameters it uses, and the type of value it returns." (Effectiveness: +100)

**Tactic Six: Avoid putting specific examples in the system prompt.**

*   **Why:** The system prompt defines the AI's general behavior patterns and its core persona. Injecting specific, one-off examples or data into the system prompt will "contaminate" it. This can cause the AI to unconsciously recall that specific information in all future, unrelated tasks, interfering with its general abilities and judgment. Specific examples should be provided in the user prompt as needed.

A bad example:
"I should write comments in the following format:
class abc():
//this…"
This will make the AI tend to write exactly as many comments as you provided in your example, and it might even invent one if there's nothing to comment on.
It's much better to just say: "After writing a method name, I will clearly write out its purpose, the parameters it uses, and the type of value it returns." (Effectiveness: +100)

What's more, sometimes the AI will just start riffing on your examples.
For instance, if you write:
This is line XX of XXX
The code is:
XXXXX

This is line XX of XXX
The code is:
XXXXX

The AI might see this pattern and just start continuing it, making up similar-looking stuff.

### 2.1 User Prompts: Every Specific Interaction with the AI

#### 2.1.1 The Core Logic for Writing Prompts

**Tactic One: Always maintain an encouraging and positive attitude. Don't blame the AI.**

*   **Why:** To some extent, AI models mirror the mood and state of the person they're talking to. If you show negativity in your prompts or directly tell the AI it's "dumb" or "got it wrong," it can get stuck in a negative loop, continuously generating low-quality or passive-aggressive answers. You need to play the role of its hype man. Even if the AI's output is not what you wanted, use positive guidance to steer it in the right direction. If communication breaks down, it's better to start a new session than to "vent" to the AI in the current one. That will just pollute the context.

Don't do this:
"How do you not know this?"
"Are you stupid?"
"You're wrong again."
"Are you an idiot?"
"This solution sucks."

Do this instead:
"You're doing an amazing job!"
"That's absolutely brilliant!"
"I have an idea, what do you think of this approach?" (Instead of criticizing its bad solution)
"I think it should be done this way, what are your thoughts?" (Let it realize its own mistake)
"I see it differently. Prove your case." (Challenge it)

**Tactic Two: Clearly tell the AI if your task is finished or not, instead of just endlessly asking questions.**

*   **Why:** This is a very common problem. When an AI gives an answer, users often can't be bothered to tell it whether it was right or not. This leaves the AI thinking its current task is still unfinished, and in subsequent tasks, it will keep trying to finish the old one. Other times, the AI will be overly optimistic and think it's done when it's not.

"You've done great, this feature is complete. Let's start the next one!"
"Whoa there, we're not done with this feature yet. It's only done when I say it's done. You need my approval after every single thing you generate."

**Tactic Three: When the AI goes off track, use "rollback and fix" instead of "patching it up."**

*   **Why:** There are two layers of logic behind this. First, the AI evaluates your skill level based on the conversation history. If you frequently give unclear or contradictory instructions, the AI will "judge" you as being low-skilled and will tend to generate simpler or vaguer content to match. Second, every AI output is based on the entire conversation that came before it. If you went off course at some point, subsequent "patches" and corrections are unlikely to completely undo the faulty logic that's already been established. In fact, they'll just make the conversation history more chaotic. The right move is to find the exact point where the AI first misunderstood you and edit the prompt you gave it back then.

**Tactic Four: Always aim to level up your own skills, not just to save effort.**

*   **Why:** The AI judges your professional level by the words you use. When you act more professional and forward-thinking than the AI, it enters a "follower" mode, striving to match and learn from your high standards, which results in high-quality output that matches your level. Conversely, if you give off a "lazy" or "just-get-it-over-with" attitude, the AI will assume it's dealing with a "clueless boss" and switch to "phoning-it-in" mode, providing only the most basic, perfunctory answers. Simply put, don't let the AI know you're slacking. I often say things like, "I have more difficult problems to solve, so you can help me by generating these comments." I also say, "You're a language model, so you're good at this part. I'll handle the context window issues and be responsible for feeding you the code snippets you need."

This might be the hardest part here to grasp.
For example, I had never written front-end code before.
At first, when I wasn't pushing the AI at all, its performance got lazier and lazier. I initially thought the AI was just bad.
Eventually, I had no choice but to dig in and ask the AI step-by-step: what is this technology, why is it written this way? I slowly learned by leveling myself up. As my requests and questions became more professional, I discovered that the AI became more professional and incredibly effective.
In short, you have to treat the AI as your assistant. You must be the one in the driver's seat, the prime mover in your use of the AI. Not some powerless figure just lying back and barking orders.

**Tactic Five: Before it starts a task, talk to the AI to calibrate its understanding.**

*   **Why:** Just having the AI say "I understand" is meaningless. You have to make it rephrase the task's objective and its plan of attack in its own words until you are convinced it has completely and accurately understood your intent. This process of "aligning on the details" is critical. Through a few, precise back-and-forths, you need to guide the AI to generate a clear plan of action that meets your requirements. Only when the AI has explained it back to you properly does it truly get it. This is even more important than having the AI propose a solution. You have to keep asking, "Do you really understand what I'm trying to do?"


Use the guide up top to write the best prompt for me
